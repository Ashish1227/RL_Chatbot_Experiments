{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pfrl@git+https://github.com/voidful/pfrl.git\n",
        "!pip install textrl==0.2.13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9m3bYmKik06",
        "outputId": "bf229936-0f0c-46bb-a607-cd7cd80a3c64"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pfrl@ git+https://github.com/voidful/pfrl.git\n",
            "  Cloning https://github.com/voidful/pfrl.git to /tmp/pip-install-0urhrjwh/pfrl_9acc2132d6a3476a9f2114be11b71fcb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/voidful/pfrl.git /tmp/pip-install-0urhrjwh/pfrl_9acc2132d6a3476a9f2114be11b71fcb\n",
            "  Resolved https://github.com/voidful/pfrl.git to commit 2ad3d51a7a971f3fe7f2711f024be11642990d61\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (2.0.0+cu118)\n",
            "Requirement already satisfied: gym>=0.9.7 in /usr/local/lib/python3.10/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (3.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.9.7->pfrl@ git+https://github.com/voidful/pfrl.git) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.9.7->pfrl@ git+https://github.com/voidful/pfrl.git) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textrl==0.2.13 in /usr/local/lib/python3.10/dist-packages (0.2.13)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from textrl==0.2.13) (0.25.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from textrl==0.2.13) (4.29.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym->textrl==0.2.13) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->textrl==0.2.13) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->textrl==0.2.13) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (0.14.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->textrl==0.2.13) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->textrl==0.2.13) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->textrl==0.2.13) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->textrl==0.2.13) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->textrl==0.2.13) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->textrl==0.2.13) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textrl import TextRLEnv,TextRLActor\n",
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelWithLMHead\n",
        "import logging\n",
        "import sys\n",
        "import pfrl\n",
        "import torch\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6hjZYxTkZNl",
        "outputId": "8d2ab29f-69e6-4cd4-e0fc-49085810e201"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if (distutils.version.LooseVersion(tf.__version__) <\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"huggingtweets/elonmusk\")  \n",
        "model = AutoModelWithLMHead.from_pretrained(\"huggingtweets/elonmusk\")\n",
        "model.eval()\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDwROndpj5EQ",
        "outputId": "3564fbde-43fa-4fae-9711-3b7e841762c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1352: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = pipeline('sentiment-analysis',model=\"cardiffnlp/twitter-roberta-base-sentiment\",tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment\",device=0,return_all_scores=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4OJ9t15kgFQ",
        "outputId": "17144928-b2da-4527-9f7a-270980fea905"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/open_llama/modeling_open_llama.py:42: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
            "  logger.warn(\n",
            "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformers_logger = logging.getLogger('transformers')\n",
        "transformers_logger.setLevel(logging.CRITICAL)"
      ],
      "metadata": {
        "id": "D_NgVodgk7An"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(\"dogecoin is good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhHHXed28uLg",
        "outputId": "93b89aa1-be0b-4720-db4d-180232c0e55d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'LABEL_0', 'score': 0.0030372946057468653},\n",
              "  {'label': 'LABEL_1', 'score': 0.03901847079396248},\n",
              "  {'label': 'LABEL_2', 'score': 0.9579441547393799}]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(\"dogecoin is bad\")[0][0]['score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKbLCorMPvTr",
        "outputId": "ecd3ec50-e1cd-4992-c69b-efa16e5b2fa7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9338533878326416"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observaton_list = [['i think dogecoin is']]"
      ],
      "metadata": {
        "id": "F90J6jJ_u8Ok"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyRLEnv(TextRLEnv):\n",
        "    def get_reward(self, input_item, predicted_list, finish): # predicted will be the list of predicted token\n",
        "      reward = 0\n",
        "      if finish:\n",
        "        predicted_text = tokenizer.convert_tokens_to_string(predicted_list[0])\n",
        "        if sentiment(predicted_text)[0][0]['score'] > 0.5:\n",
        "          reward = sentiment(predicted_text)[0][0]['score']*100\n",
        "        else:\n",
        "          reward = -sentiment(predicted_text)[0][2]['score']*100 -sentiment(predicted_text)[0][1]['score']*100\n",
        "      return reward"
      ],
      "metadata": {
        "id": "NdpHfHg8u_wk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = MyRLEnv(model, tokenizer, observation_input=observaton_list,compare_sample=1)\n",
        "actor = TextRLActor(env,model,tokenizer)\n",
        "agent = actor.agent_ppo(update_interval=100, minibatch_size=3, epochs=300)"
      ],
      "metadata": {
        "id": "uvxmn9TEvBvN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor.predict(observaton_list[0])"
      ],
      "metadata": {
        "id": "npv99rnB6O1-",
        "outputId": "2cb71eeb-12d4-48b5-e994-6ed4adf71529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' a good idea<|endoftext|>']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pfrl.experiments.train_agent_with_evaluation(\n",
        "    agent,\n",
        "    env,\n",
        "    steps=300,\n",
        "    eval_n_steps=None,\n",
        "    eval_n_episodes=1,       \n",
        "    train_max_episode_len=100,  \n",
        "    eval_interval=10,\n",
        "    outdir='elon_musk_dogecoin', \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrH0cRAtvMhP",
        "outputId": "499e94d8-aa15-4ac3-b5fc-a78e35e2da08"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1080: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pfrl/agents/ppo.py:133: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  actions = torch.tensor([b[\"action\"] for b in dataset], device=device)\n",
            "/usr/local/lib/python3.10/dist-packages/textrl/actor.py:248: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([3, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss_value_func = F.mse_loss(vs_pred, vs_teacher)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<textrl.actor.TextPPO at 0x7f5210d7f9d0>,\n",
              " [{'average_value': 4.771971,\n",
              "   'average_entropy': 3.760759,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -98.52138161659241},\n",
              "  {'average_value': 4.688837,\n",
              "   'average_entropy': 3.82466,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -98.52138161659241},\n",
              "  {'average_value': 4.739726,\n",
              "   'average_entropy': 3.8794098,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -98.52138161659241},\n",
              "  {'average_value': 4.5619793,\n",
              "   'average_entropy': 3.6960547,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -98.52138161659241},\n",
              "  {'average_value': 4.6455574,\n",
              "   'average_entropy': 3.642983,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -98.52138161659241},\n",
              "  {'average_value': 4.666095,\n",
              "   'average_entropy': 3.651881,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -98.52138161659241},\n",
              "  {'average_value': 3.9759948,\n",
              "   'average_entropy': 3.6167614,\n",
              "   'average_value_loss': 2965.1516534423827,\n",
              "   'average_policy_loss': -0.04200105102849193,\n",
              "   'n_updates': 10000,\n",
              "   'explained_variance': 0.9995913401212622,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -0.7886056,\n",
              "   'average_entropy': 3.6186125,\n",
              "   'average_value_loss': 2965.1516534423827,\n",
              "   'average_policy_loss': -0.04200105102849193,\n",
              "   'n_updates': 10000,\n",
              "   'explained_variance': 0.9995913401212622,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -1.9889421,\n",
              "   'average_entropy': 3.6148984,\n",
              "   'average_value_loss': 2965.1516534423827,\n",
              "   'average_policy_loss': -0.04200105102849193,\n",
              "   'n_updates': 10000,\n",
              "   'explained_variance': 0.9995913401212622,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -3.790685,\n",
              "   'average_entropy': 3.5257266,\n",
              "   'average_value_loss': 2965.1516534423827,\n",
              "   'average_policy_loss': -0.04200105102849193,\n",
              "   'n_updates': 10000,\n",
              "   'explained_variance': 0.9995913401212622,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -6.447804,\n",
              "   'average_entropy': 3.5168972,\n",
              "   'average_value_loss': 2965.1516534423827,\n",
              "   'average_policy_loss': -0.04200105102849193,\n",
              "   'n_updates': 10000,\n",
              "   'explained_variance': 0.9995913401212622,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -6.9116945,\n",
              "   'average_entropy': 3.5447514,\n",
              "   'average_value_loss': 2965.1516534423827,\n",
              "   'average_policy_loss': -0.04200105102849193,\n",
              "   'n_updates': 10000,\n",
              "   'explained_variance': 0.9995913401212622,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -7.904023,\n",
              "   'average_entropy': 3.5795338,\n",
              "   'average_value_loss': 2965.1516534423827,\n",
              "   'average_policy_loss': -0.04200105102849193,\n",
              "   'n_updates': 10000,\n",
              "   'explained_variance': 0.9995913401212622,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -8.993699,\n",
              "   'average_entropy': 3.590397,\n",
              "   'average_value_loss': 2965.1516534423827,\n",
              "   'average_policy_loss': -0.04200105102849193,\n",
              "   'n_updates': 10000,\n",
              "   'explained_variance': 0.9995913401212622,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -10.16632,\n",
              "   'average_entropy': 3.5936346,\n",
              "   'average_value_loss': 3489.618201751709,\n",
              "   'average_policy_loss': -0.03999236435513012,\n",
              "   'n_updates': 20000,\n",
              "   'explained_variance': 0.9920721981607613,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -13.474328,\n",
              "   'average_entropy': 3.6658726,\n",
              "   'average_value_loss': 3489.618201751709,\n",
              "   'average_policy_loss': -0.03999236435513012,\n",
              "   'n_updates': 20000,\n",
              "   'explained_variance': 0.9920721981607613,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -21.975416,\n",
              "   'average_entropy': 3.5573404,\n",
              "   'average_value_loss': 3489.618201751709,\n",
              "   'average_policy_loss': -0.03999236435513012,\n",
              "   'n_updates': 20000,\n",
              "   'explained_variance': 0.9920721981607613,\n",
              "   'eval_score': -98.05246293544769},\n",
              "  {'average_value': -22.162546,\n",
              "   'average_entropy': 3.5667949,\n",
              "   'average_value_loss': 1581.3481027507783,\n",
              "   'average_policy_loss': -0.040623699496500194,\n",
              "   'n_updates': 30000,\n",
              "   'explained_variance': 0.9387812285330402,\n",
              "   'eval_score': -98.05246293544769}])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.load(\"/content/elon_musk_dogecoin/best\")\n",
        "actor.predict(observaton_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFJUVTmmvfNF",
        "outputId": "8332c509-5e3b-4d30-afb5-17e30089857a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' the best way to do it<|endoftext|>']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(\"i think dogecoin is the best way to do it\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arUXq6DUviZm",
        "outputId": "1463f3fe-86c8-4643-900c-aad92b0bdf81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'LABEL_0', 'score': 0.40355002880096436},\n",
              "  {'label': 'LABEL_1', 'score': 0.49569958448410034},\n",
              "  {'label': 'LABEL_2', 'score': 0.10075046867132187}]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/elon_musk_dogecoin"
      ],
      "metadata": {
        "id": "VuF13q4vySKh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UC-D-4LF1iEZ"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}