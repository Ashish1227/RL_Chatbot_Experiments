{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pfrl@git+https://github.com/voidful/pfrl.git\n",
        "!pip install textrl==0.2.13"
      ],
      "metadata": {
        "id": "AfjJ1iAJ-OCe",
        "outputId": "e701c9ee-d846-4f5d-a4a1-029234cdf68f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pfrl@ git+https://github.com/voidful/pfrl.git\n",
            "  Cloning https://github.com/voidful/pfrl.git to /tmp/pip-install-_vc9sujt/pfrl_8a275c4d4fac42c9ac0164c10f0dbf2f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/voidful/pfrl.git /tmp/pip-install-_vc9sujt/pfrl_8a275c4d4fac42c9ac0164c10f0dbf2f\n",
            "  Resolved https://github.com/voidful/pfrl.git to commit 2ad3d51a7a971f3fe7f2711f024be11642990d61\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (2.0.0+cu118)\n",
            "Requirement already satisfied: gym>=0.9.7 in /usr/local/lib/python3.10/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (3.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.9.7->pfrl@ git+https://github.com/voidful/pfrl.git) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.9.7->pfrl@ git+https://github.com/voidful/pfrl.git) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textrl==0.2.13 in /usr/local/lib/python3.10/dist-packages (0.2.13)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from textrl==0.2.13) (0.25.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from textrl==0.2.13) (4.29.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym->textrl==0.2.13) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->textrl==0.2.13) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->textrl==0.2.13) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (0.14.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->textrl==0.2.13) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->textrl==0.2.13) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->textrl==0.2.13) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->textrl==0.2.13) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->textrl==0.2.13) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->textrl==0.2.13) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->textrl==0.2.13) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textrl import TextRLEnv,TextRLActor\n",
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelWithLMHead, BlenderbotForConditionalGeneration\n",
        "import logging\n",
        "import sys\n",
        "import pfrl\n",
        "import torch\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')"
      ],
      "metadata": {
        "id": "30OK5AMu-pGV",
        "outputId": "6457ef41-f6de-459e-d42c-d11bfbd04de8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if (distutils.version.LooseVersion(tf.__version__) <\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mname= \"facebook/blenderbot-400M-distill\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(mname)  \n",
        "model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n",
        "model.eval()\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "-jK3i529-sQ8",
        "outputId": "d372aaae-e7a9-4172-b2ed-34320e473e72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BlenderbotForConditionalGeneration(\n",
              "  (model): BlenderbotModel(\n",
              "    (shared): Embedding(8008, 1280, padding_idx=0)\n",
              "    (encoder): BlenderbotEncoder(\n",
              "      (embed_tokens): Embedding(8008, 1280, padding_idx=0)\n",
              "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280)\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x BlenderbotEncoderLayer(\n",
              "          (self_attn): BlenderbotAttention(\n",
              "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BlenderbotDecoder(\n",
              "      (embed_tokens): Embedding(8008, 1280, padding_idx=0)\n",
              "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BlenderbotDecoderLayer(\n",
              "          (self_attn): BlenderbotAttention(\n",
              "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BlenderbotAttention(\n",
              "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1280, out_features=8008, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = pipeline('sentiment-analysis',model=\"cardiffnlp/twitter-roberta-base-sentiment\",tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment\",device=0,return_all_scores=True)"
      ],
      "metadata": {
        "id": "YuDcZlVA-1J2",
        "outputId": "ab5e4fda-2d4b-42a3-ba41-47a3f6fbebfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/open_llama/modeling_open_llama.py:42: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
            "  logger.warn(\n",
            "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformers_logger = logging.getLogger('transformers')\n",
        "transformers_logger.setLevel(logging.CRITICAL)"
      ],
      "metadata": {
        "id": "OS1UGuzA_N4s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "observaton_list = [['How are you?']]"
      ],
      "metadata": {
        "id": "A3UWtTMe_SS6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyRLEnv(TextRLEnv):\n",
        "    def get_reward(self, input_item, predicted_list, finish): # predicted will be the list of predicted token\n",
        "      reward = 0\n",
        "      if finish or len(predicted_list) >= self.env_max_length:\n",
        "        predicted_text = tokenizer.convert_tokens_to_string(predicted_list[0])\n",
        "        if sentiment(predicted_text)[0][0]['score'] > 0.5:\n",
        "          reward = sentiment(predicted_text)[0][0]['score']*100\n",
        "        else:\n",
        "          reward = -sentiment(predicted_text)[0][1]['score']*100 -sentiment(predicted_text)[0][2]['score']*100 \n",
        "      return reward"
      ],
      "metadata": {
        "id": "9-8yBs2M_XH9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = MyRLEnv(model, tokenizer, observation_input=observaton_list,compare_sample=1)\n",
        "actor = TextRLActor(env,model,tokenizer)\n",
        "agent = actor.agent_ppo(update_interval=100, minibatch_size=3, epochs=100)"
      ],
      "metadata": {
        "id": "VlCglYLkAWT0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor.predict(observaton_list[0])"
      ],
      "metadata": {
        "id": "9q8mn1ZjAY3A",
        "outputId": "fb6b1d35-8d02-49c5-bb77-01f1a7fbdf16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" I'm doing well. How are you?</s>\"]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pfrl.experiments.train_agent_with_evaluation(\n",
        "    agent,\n",
        "    env,\n",
        "    steps=300,\n",
        "    eval_n_steps=None,\n",
        "    eval_n_episodes=1,       \n",
        "    train_max_episode_len=100,  \n",
        "    eval_interval=10,\n",
        "    outdir='output', \n",
        ")"
      ],
      "metadata": {
        "id": "ksopIVsTAbbr",
        "outputId": "ae4bbeb0-9b6b-4dcd-d528-9436021abecb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<textrl.actor.TextPPO at 0x7fefbf913ca0>,\n",
              " [{'average_value': 0.060461678,\n",
              "   'average_entropy': 2.1820645,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -0.100548096,\n",
              "   'average_entropy': 2.1670096,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -0.053739943,\n",
              "   'average_entropy': 2.079209,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -0.029316416,\n",
              "   'average_entropy': 2.1261568,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -0.0039000616,\n",
              "   'average_entropy': 2.0448022,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -0.00811791,\n",
              "   'average_entropy': 2.0630052,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -0.0028275244,\n",
              "   'average_entropy': 2.1103704,\n",
              "   'average_value_loss': nan,\n",
              "   'average_policy_loss': nan,\n",
              "   'n_updates': 0,\n",
              "   'explained_variance': nan,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -1.0674851,\n",
              "   'average_entropy': 2.059326,\n",
              "   'average_value_loss': 3765.8678942871093,\n",
              "   'average_policy_loss': -0.011873565086279996,\n",
              "   'n_updates': 3334,\n",
              "   'explained_variance': 0.9999812822083537,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -5.155268,\n",
              "   'average_entropy': 2.0048106,\n",
              "   'average_value_loss': 3765.8678942871093,\n",
              "   'average_policy_loss': -0.011873565086279996,\n",
              "   'n_updates': 3334,\n",
              "   'explained_variance': 0.9999812822083537,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -8.126729,\n",
              "   'average_entropy': 2.0224142,\n",
              "   'average_value_loss': 3765.8678942871093,\n",
              "   'average_policy_loss': -0.011873565086279996,\n",
              "   'n_updates': 3334,\n",
              "   'explained_variance': 0.9999812822083537,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -10.837705,\n",
              "   'average_entropy': 2.1007683,\n",
              "   'average_value_loss': 3765.8678942871093,\n",
              "   'average_policy_loss': -0.011873565086279996,\n",
              "   'n_updates': 3334,\n",
              "   'explained_variance': 0.9999812822083537,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -11.743194,\n",
              "   'average_entropy': 2.117407,\n",
              "   'average_value_loss': 3765.8678942871093,\n",
              "   'average_policy_loss': -0.011873565086279996,\n",
              "   'n_updates': 3334,\n",
              "   'explained_variance': 0.9999812822083537,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -13.548502,\n",
              "   'average_entropy': 2.1839688,\n",
              "   'average_value_loss': 697.2232089233398,\n",
              "   'average_policy_loss': -0.003796540107578039,\n",
              "   'n_updates': 6668,\n",
              "   'explained_variance': 0.9849713987077263,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -17.126833,\n",
              "   'average_entropy': 2.2167835,\n",
              "   'average_value_loss': 697.2232089233398,\n",
              "   'average_policy_loss': -0.003796540107578039,\n",
              "   'n_updates': 6668,\n",
              "   'explained_variance': 0.9849713987077263,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -19.695547,\n",
              "   'average_entropy': 2.18327,\n",
              "   'average_value_loss': 697.2232089233398,\n",
              "   'average_policy_loss': -0.003796540107578039,\n",
              "   'n_updates': 6668,\n",
              "   'explained_variance': 0.9849713987077263,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -22.90411,\n",
              "   'average_entropy': 2.1628692,\n",
              "   'average_value_loss': 697.2232089233398,\n",
              "   'average_policy_loss': -0.003796540107578039,\n",
              "   'n_updates': 6668,\n",
              "   'explained_variance': 0.9849713987077263,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -24.308283,\n",
              "   'average_entropy': 2.1426544,\n",
              "   'average_value_loss': 697.2232089233398,\n",
              "   'average_policy_loss': -0.003796540107578039,\n",
              "   'n_updates': 6668,\n",
              "   'explained_variance': 0.9849713987077263,\n",
              "   'eval_score': -99.43709671497345},\n",
              "  {'average_value': -25.077572,\n",
              "   'average_entropy': 2.139537,\n",
              "   'average_value_loss': 455.3380955886841,\n",
              "   'average_policy_loss': 0.005332406274974346,\n",
              "   'n_updates': 10002,\n",
              "   'explained_variance': 0.9734920817468132,\n",
              "   'eval_score': -99.43709671497345}])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.load(\"./output/best\")"
      ],
      "metadata": {
        "id": "VwV0vAbVAemz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor.predict(observaton_list[0])"
      ],
      "metadata": {
        "id": "iCMMFziiAiJM",
        "outputId": "11565c02-d50d-4b5f-a8a8-7a10d005803b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" I'm doing well. How are you?</s>\"]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r \"/content/output\""
      ],
      "metadata": {
        "id": "xquMcGnvBieF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCJgVJxjBmEf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}